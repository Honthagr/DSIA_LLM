{"cells":[{"cell_type":"markdown","id":"25aa40e3-5109-433f-9153-f5770531fe94","metadata":{"id":"25aa40e3-5109-433f-9153-f5770531fe94"},"source":["# Chapter 2 - Lab 1a : Working with Text\n","\n","> Author : Badr TAJINI - Large Language model (LLMs) - ESIEE 2024-2025"]},{"cell_type":"markdown","id":"c6a4048f","metadata":{"id":"c6a4048f"},"source":["#### 1. Chapter Overview\n","The notebook transitions to Chapter 2: Working with Text, introducing the key theme: preparing and processing text data for LLMs. This chapter's objective is to cover text tokenization and embedding, pivotal steps in transforming raw text into machine-readable formats"]},{"cell_type":"markdown","id":"4a4bf7b8","metadata":{"id":"4a4bf7b8"},"source":["#### 2. Checking Dependencies"]},{"cell_type":"code","source":["!pip install tiktoken"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3-uK6ISbT36B","executionInfo":{"status":"ok","timestamp":1736783810315,"user_tz":-60,"elapsed":8426,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}},"outputId":"56aa6745-a928-4a94-c27c-27e19e331228"},"id":"3-uK6ISbT36B","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tiktoken\n","  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.11.6)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.12.14)\n","Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.2 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m0.9/1.2 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tiktoken\n","Successfully installed tiktoken-0.8.0\n"]}]},{"cell_type":"code","execution_count":2,"id":"4d1305cf-12d5-46fe-a2c9-36fb71c5b3d3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4d1305cf-12d5-46fe-a2c9-36fb71c5b3d3","executionInfo":{"status":"ok","timestamp":1736783810316,"user_tz":-60,"elapsed":22,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}},"outputId":"cea91615-a055-433c-d84f-e67ba44bba0a"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch version: 2.5.1+cu121\n","tiktoken version: 0.8.0\n"]}],"source":["from importlib.metadata import version\n","\n","print(\"torch version:\", version(\"torch\"))\n","print(\"tiktoken version:\", version(\"tiktoken\"))"]},{"cell_type":"markdown","id":"34032af9","metadata":{"id":"34032af9"},"source":["This cell verifies the installed versions of essential libraries: PyTorch for deep learning and tiktoken for optimized BPE tokenization. Ensuring compatibility between code and library versions is critical in machine learning workflows to maintain reproducibility and prevent errors during execution."]},{"cell_type":"markdown","id":"4e47ac09","metadata":{"id":"4e47ac09"},"source":["#### - Chapter Overview"]},{"cell_type":"markdown","id":"5a42fbfd-e3c2-43c2-bc12-f5f870a0b10a","metadata":{"id":"5a42fbfd-e3c2-43c2-bc12-f5f870a0b10a"},"source":["- This chapter covers data preparation and sampling to get input data \"ready\" for the LLM"]},{"cell_type":"markdown","id":"628b2922-594d-4ff9-bd82-04f1ebdf41f5","metadata":{"id":"628b2922-594d-4ff9-bd82-04f1ebdf41f5"},"source":["<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/01.webp?timestamp=1\" width=\"500px\">"]},{"cell_type":"markdown","id":"2417139b-2357-44d2-bd67-23f5d7f52ae7","metadata":{"id":"2417139b-2357-44d2-bd67-23f5d7f52ae7"},"source":["## 2.1 Understanding word embeddings"]},{"cell_type":"markdown","id":"4f69dab7-a433-427a-9e5b-b981062d6296","metadata":{"id":"4f69dab7-a433-427a-9e5b-b981062d6296"},"source":["- There are many forms of embeddings; we focus on text embeddings for now."]},{"cell_type":"markdown","id":"ba08d16f-f237-4166-bf89-0e9fe703e7b4","metadata":{"id":"ba08d16f-f237-4166-bf89-0e9fe703e7b4"},"source":["<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/02.webp\" width=\"500px\">"]},{"cell_type":"markdown","id":"288c4faf-b93a-4616-9276-7a4aa4b5e9ba","metadata":{"id":"288c4faf-b93a-4616-9276-7a4aa4b5e9ba"},"source":["- LLMs work with embeddings in high-dimensional spaces (i.e., thousands of dimensions)\n","- Since we can't visualize such high-dimensional spaces (we humans think in 1, 2, or 3 dimensions), the figure below illustrates a 2-dimensional embedding space"]},{"cell_type":"markdown","id":"d6b80160-1f10-4aad-a85e-9c79444de9e6","metadata":{"id":"d6b80160-1f10-4aad-a85e-9c79444de9e6"},"source":["<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/03.webp\" width=\"300px\">"]},{"cell_type":"markdown","id":"eddbb984-8d23-40c5-bbfa-c3c379e7eec3","metadata":{"id":"eddbb984-8d23-40c5-bbfa-c3c379e7eec3"},"source":["## 2.2 Tokenizing text"]},{"cell_type":"markdown","id":"f9c90731-7dc9-4cd3-8c4a-488e33b48e80","metadata":{"id":"f9c90731-7dc9-4cd3-8c4a-488e33b48e80"},"source":["- In this section, we tokenize text, which means breaking text into smaller units, such as individual words and punctuation characters"]},{"cell_type":"markdown","id":"09872fdb-9d4e-40c4-949d-52a01a43ec4b","metadata":{"id":"09872fdb-9d4e-40c4-949d-52a01a43ec4b"},"source":["<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/04.webp\" width=\"300px\">"]},{"cell_type":"markdown","id":"ddd3abdf","metadata":{"id":"ddd3abdf"},"source":["#### - Downloading the Dataset"]},{"cell_type":"markdown","id":"8cceaa18-833d-46b6-b211-b20c53902805","metadata":{"id":"8cceaa18-833d-46b6-b211-b20c53902805"},"source":["- Load raw text we want to work with\n","- [The Verdict by Edith Wharton](https://en.wikisource.org/wiki/The_Verdict) is a public domain short story"]},{"cell_type":"code","execution_count":3,"id":"40f9d9b1-6d32-485a-825a-a95392a86d79","metadata":{"id":"40f9d9b1-6d32-485a-825a-a95392a86d79","executionInfo":{"status":"ok","timestamp":1736783810790,"user_tz":-60,"elapsed":487,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}}},"outputs":[],"source":["import os\n","import urllib.request\n","\n","if not os.path.exists(\"the-verdict.txt\"):\n","    url = (\"https://raw.githubusercontent.com/rasbt/\"\n","           \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n","           \"the-verdict.txt\")\n","    file_path = \"the-verdict.txt\"\n","    urllib.request.urlretrieve(url, file_path)"]},{"cell_type":"markdown","id":"91a19e7f","metadata":{"id":"91a19e7f"},"source":["This block downloads \"The Verdict\" by Edith Wharton, a public domain text, as the source material for tokenization. Using authentic literary text mirrors real-world preprocessing needs for varied and complex datasets."]},{"cell_type":"markdown","id":"d91c8b8f","metadata":{"id":"d91c8b8f"},"source":["#### - Reading the Dataset"]},{"cell_type":"code","execution_count":4,"id":"8a769e87-470a-48b9-8bdb-12841b416198","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8a769e87-470a-48b9-8bdb-12841b416198","executionInfo":{"status":"ok","timestamp":1736783810790,"user_tz":-60,"elapsed":74,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}},"outputId":"13dcd016-ecdb-4ce9-be64-2a1c629dad4e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of character: 20479\n","I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"]}],"source":["with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n","    raw_text = f.read()\n","\n","print(\"Total number of character:\", len(raw_text))\n","print(raw_text[:99])"]},{"cell_type":"markdown","id":"7aa9febf","metadata":{"id":"7aa9febf"},"source":["The raw text is loaded and briefly inspected for size and content. The total character count is a useful metric for gauging the scope of preprocessing and tokenization steps.\n"]},{"cell_type":"markdown","id":"9b971a46-ac03-4368-88ae-3f20279e8f4e","metadata":{"id":"9b971a46-ac03-4368-88ae-3f20279e8f4e"},"source":["- The goal is to tokenize and embed this text for an LLM\n","- Let's develop a simple tokenizer based on some simple sample text that we can then later apply to the text above\n","- The following regular expression will split on whitespaces"]},{"cell_type":"markdown","id":"7d54f79d","metadata":{"id":"7d54f79d"},"source":["#### - Whitespace Splitting"]},{"cell_type":"code","execution_count":5,"id":"737dd5b0-9dbb-4a97-9ae4-3482c8c04be7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"737dd5b0-9dbb-4a97-9ae4-3482c8c04be7","executionInfo":{"status":"ok","timestamp":1736783810790,"user_tz":-60,"elapsed":69,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}},"outputId":"0e1cbe34-ddd3-4380-cd34-27a8eb4bf77f"},"outputs":[{"output_type":"stream","name":"stdout","text":["['Hello,', ' ', 'world.', ' ', 'This,', ' ', 'is', ' ', 'a', ' ', 'test.']\n"]}],"source":["import re\n","\n","text = \"Hello, world. This, is a test.\"\n","result = re.split(r'(\\s)', text)\n","\n","print(result)"]},{"cell_type":"markdown","id":"7ff84feb","metadata":{"id":"7ff84feb"},"source":["This initial implementation splits text on whitespace, creating a basic tokenization strategy. While rudimentary, it lays the groundwork for iterative refinement, which is expanded upon in subsequent cells."]},{"cell_type":"markdown","id":"8ffc5abd","metadata":{"id":"8ffc5abd"},"source":["#### - Including Punctuation in Tokenization"]},{"cell_type":"markdown","id":"a8c40c18-a9d5-4703-bf71-8261dbcc5ee3","metadata":{"id":"a8c40c18-a9d5-4703-bf71-8261dbcc5ee3"},"source":["- We don't only want to split on whitespaces but also commas and periods, so let's modify the regular expression to do that as well"]},{"cell_type":"code","execution_count":6,"id":"ea02489d-01f9-4247-b7dd-a0d63f62ef07","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ea02489d-01f9-4247-b7dd-a0d63f62ef07","executionInfo":{"status":"ok","timestamp":1736783810791,"user_tz":-60,"elapsed":61,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}},"outputId":"9c2ab8fc-d065-4821-80e0-c1a7bcd1bbeb"},"outputs":[{"output_type":"stream","name":"stdout","text":["['Hello', ',', '', ' ', 'world', '.', '', ' ', 'This', ',', '', ' ', 'is', ' ', 'a', ' ', 'test', '.', '']\n"]}],"source":["result = re.split(r'([,.]|\\s)', text)\n","\n","print(result)"]},{"cell_type":"markdown","id":"785520f9","metadata":{"id":"785520f9"},"source":["The updated regular expression accounts for punctuation, an improvement that aligns token boundaries more closely with linguistic conventions."]},{"cell_type":"markdown","id":"58875bac","metadata":{"id":"58875bac"},"source":["#### - Cleaning Empty Tokens"]},{"cell_type":"markdown","id":"461d0c86-e3af-4f87-8fae-594a9ca9b6ad","metadata":{"id":"461d0c86-e3af-4f87-8fae-594a9ca9b6ad"},"source":["- As we can see, this creates empty strings, let's remove them"]},{"cell_type":"code","execution_count":7,"id":"4d8a6fb7-2e62-4a12-ad06-ccb04f25fed7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4d8a6fb7-2e62-4a12-ad06-ccb04f25fed7","executionInfo":{"status":"ok","timestamp":1736783810791,"user_tz":-60,"elapsed":54,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}},"outputId":"8dee12ce-d599-4757-a527-cec61703ef4c"},"outputs":[{"output_type":"stream","name":"stdout","text":["['Hello', ',', 'world', '.', 'This', ',', 'is', 'a', 'test', '.']\n"]}],"source":["# Strip whitespace from each item and then filter out any empty strings.\n","result = [item for item in result if item.strip()]\n","print(result)"]},{"cell_type":"markdown","id":"443508fb","metadata":{"id":"443508fb"},"source":["Empty strings resulting from consecutive delimiters are removed to streamline the output. This step ensures that each token contributes meaningful information to downstream tasks."]},{"cell_type":"markdown","id":"1593107e","metadata":{"id":"1593107e"},"source":["\n","#### - Advanced Tokenization : Generalizing Tokenization"]},{"cell_type":"markdown","id":"250e8694-181e-496f-895d-7cb7d92b5562","metadata":{"id":"250e8694-181e-496f-895d-7cb7d92b5562"},"source":["- This looks pretty good, but let's also handle other types of punctuation, such as periods, question marks, and so on"]},{"cell_type":"code","execution_count":8,"id":"ed3a9467-04b4-49d9-96c5-b8042bcf8374","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ed3a9467-04b4-49d9-96c5-b8042bcf8374","executionInfo":{"status":"ok","timestamp":1736783810792,"user_tz":-60,"elapsed":50,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}},"outputId":"f4f516cf-5830-44bf-b03d-e0cf1daf7214"},"outputs":[{"output_type":"stream","name":"stdout","text":["['Hello', ',', 'world', '.', 'Is', 'this', '--', 'a', 'test', '?']\n"]}],"source":["text = \"Hello, world. Is this-- a test?\"\n","\n","result = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n","result = [item.strip() for item in result if item.strip()]\n","print(result)"]},{"cell_type":"markdown","id":"b4f844a7","metadata":{"id":"b4f844a7"},"source":["By incorporating additional delimiters (e.g., semicolons, question marks, and dashes), the tokenizer becomes robust to diverse textual inputs, making it applicable to a wider range of datasets."]},{"cell_type":"markdown","id":"0057b233","metadata":{"id":"0057b233"},"source":["#### - Tokenizing the Entire Text"]},{"cell_type":"markdown","id":"5bbea70b-c030-45d9-b09d-4318164c0bb4","metadata":{"id":"5bbea70b-c030-45d9-b09d-4318164c0bb4"},"source":["- This is pretty good, and we are now ready to apply this tokenization to the raw text"]},{"cell_type":"markdown","id":"6cbe9330-b587-4262-be9f-497a84ec0e8a","metadata":{"id":"6cbe9330-b587-4262-be9f-497a84ec0e8a"},"source":["<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/05.webp\" width=\"350px\">"]},{"cell_type":"code","execution_count":9,"id":"8c567caa-8ff5-49a8-a5cc-d365b0a78a99","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8c567caa-8ff5-49a8-a5cc-d365b0a78a99","executionInfo":{"status":"ok","timestamp":1736783810792,"user_tz":-60,"elapsed":44,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}},"outputId":"fdc3f9dd-8235-47f9-b174-577947c7380f"},"outputs":[{"output_type":"stream","name":"stdout","text":["['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"]}],"source":["preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n","preprocessed = [item.strip() for item in preprocessed if item.strip()]\n","print(preprocessed[:30])"]},{"cell_type":"markdown","id":"60206aeb","metadata":{"id":"60206aeb"},"source":["The tokenizer is applied to the downloaded dataset, producing a list of cleaned tokens. This prepares the text for subsequent embedding and modeling."]},{"cell_type":"markdown","id":"f4f5a906","metadata":{"id":"f4f5a906"},"source":["#### - Vocabulary Creation"]},{"cell_type":"markdown","id":"e2a19e1a-5105-4ddb-812a-b7d3117eab95","metadata":{"id":"e2a19e1a-5105-4ddb-812a-b7d3117eab95"},"source":["- Let's calculate the total number of tokens"]},{"cell_type":"code","execution_count":10,"id":"35db7b5e-510b-4c45-995f-f5ad64a8e19c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"35db7b5e-510b-4c45-995f-f5ad64a8e19c","executionInfo":{"status":"ok","timestamp":1736783810793,"user_tz":-60,"elapsed":39,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}},"outputId":"df02047e-2d08-4903-d2fa-1c21cf2dc4e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["4690\n"]}],"source":["print(len(preprocessed))"]},{"cell_type":"markdown","id":"0b5ce8fe-3a07-4f2a-90f1-a0321ce3a231","metadata":{"id":"0b5ce8fe-3a07-4f2a-90f1-a0321ce3a231"},"source":["## 2.3 Converting tokens into token IDs"]},{"cell_type":"markdown","id":"a5204973-f414-4c0d-87b0-cfec1f06e6ff","metadata":{"id":"a5204973-f414-4c0d-87b0-cfec1f06e6ff"},"source":["- Next, we convert the text tokens into token IDs that we can process via embedding layers later"]},{"cell_type":"markdown","id":"177b041d-f739-43b8-bd81-0443ae3a7f8d","metadata":{"id":"177b041d-f739-43b8-bd81-0443ae3a7f8d"},"source":["<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/06.webp\" width=\"500px\">"]},{"cell_type":"markdown","id":"62e4da5c","metadata":{"id":"62e4da5c"},"source":["#### - Vocabulary Creation : Building a Vocabulary"]},{"cell_type":"markdown","id":"b5973794-7002-4202-8b12-0900cd779720","metadata":{"id":"b5973794-7002-4202-8b12-0900cd779720"},"source":["- From these tokens, we can now build a vocabulary that consists of all the unique tokens"]},{"cell_type":"code","execution_count":11,"id":"7fdf0533-5ab6-42a5-83fa-a3b045de6396","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7fdf0533-5ab6-42a5-83fa-a3b045de6396","executionInfo":{"status":"ok","timestamp":1736783810793,"user_tz":-60,"elapsed":34,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}},"outputId":"16bbc3ae-86d3-4de8-a305-35cbe7ddaa0b"},"outputs":[{"output_type":"stream","name":"stdout","text":["1130\n"]}],"source":["all_words = sorted(set(preprocessed))\n","vocab_size = len(all_words)\n","\n","print(vocab_size)"]},{"cell_type":"code","execution_count":12,"id":"77d00d96-881f-4691-bb03-84fec2a75a26","metadata":{"id":"77d00d96-881f-4691-bb03-84fec2a75a26","executionInfo":{"status":"ok","timestamp":1736783810793,"user_tz":-60,"elapsed":27,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}}},"outputs":[],"source":["vocab = {token:integer for integer,token in enumerate(all_words)}"]},{"cell_type":"markdown","id":"da29f46e","metadata":{"id":"da29f46e"},"source":["A vocabulary is created by extracting all unique tokens from the dataset. Each token is assigned an integer ID, which allows numerical representation of text for computational processing. The size of the vocabulary is a key parameter that impacts the complexity and efficiency of the model."]},{"cell_type":"markdown","id":"7b078cea","metadata":{"id":"7b078cea"},"source":["#### - Vocabulary Inspection"]},{"cell_type":"markdown","id":"75bd1f81-3a8f-4dd9-9dd6-e75f32dacbe3","metadata":{"id":"75bd1f81-3a8f-4dd9-9dd6-e75f32dacbe3"},"source":["- Below are the first 50 entries in this vocabulary:"]},{"cell_type":"code","execution_count":13,"id":"e1c5de4a-aa4e-4aec-b532-10bb364039d6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e1c5de4a-aa4e-4aec-b532-10bb364039d6","executionInfo":{"status":"ok","timestamp":1736783810793,"user_tz":-60,"elapsed":26,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}},"outputId":"2682144b-e29e-47a9-bd04-2e5c84d8c003"},"outputs":[{"output_type":"stream","name":"stdout","text":["('!', 0)\n","('\"', 1)\n","(\"'\", 2)\n","('(', 3)\n","(')', 4)\n","(',', 5)\n","('--', 6)\n","('.', 7)\n","(':', 8)\n","(';', 9)\n","('?', 10)\n","('A', 11)\n","('Ah', 12)\n","('Among', 13)\n","('And', 14)\n","('Are', 15)\n","('Arrt', 16)\n","('As', 17)\n","('At', 18)\n","('Be', 19)\n","('Begin', 20)\n","('Burlington', 21)\n","('But', 22)\n","('By', 23)\n","('Carlo', 24)\n","('Chicago', 25)\n","('Claude', 26)\n","('Come', 27)\n","('Croft', 28)\n","('Destroyed', 29)\n","('Devonshire', 30)\n","('Don', 31)\n","('Dubarry', 32)\n","('Emperors', 33)\n","('Florence', 34)\n","('For', 35)\n","('Gallery', 36)\n","('Gideon', 37)\n","('Gisburn', 38)\n","('Gisburns', 39)\n","('Grafton', 40)\n","('Greek', 41)\n","('Grindle', 42)\n","('Grindles', 43)\n","('HAD', 44)\n","('Had', 45)\n","('Hang', 46)\n","('Has', 47)\n","('He', 48)\n","('Her', 49)\n","('Hermia', 50)\n"]}],"source":["for i, item in enumerate(vocab.items()):\n","    print(item)\n","    if i >= 50:\n","        break"]},{"cell_type":"markdown","id":"edf41a14","metadata":{"id":"edf41a14"},"source":["Purpose: The loop iterates through the vocabulary dictionary, printing the first 50 token-ID pairs. This provides a snapshot of the vocabulary and helps identify patterns or anomalies."]},{"cell_type":"markdown","id":"8b07c210","metadata":{"id":"8b07c210"},"source":["#### - Illustration of Tokenization"]},{"cell_type":"markdown","id":"3b1dc314-351b-476a-9459-0ec9ddc29b19","metadata":{"id":"3b1dc314-351b-476a-9459-0ec9ddc29b19"},"source":["- Below, we illustrate the tokenization of a short sample text using a small vocabulary:"]},{"cell_type":"markdown","id":"67407a9f-0202-4e7c-9ed7-1b3154191ebc","metadata":{"id":"67407a9f-0202-4e7c-9ed7-1b3154191ebc"},"source":["<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/07.webp?123\" width=\"500px\">"]},{"cell_type":"markdown","id":"ac397af8","metadata":{"id":"ac397af8"},"source":["Significance: By tokenizing a sample text, it becomes clear how the tokenizer operates and segments the text into tokens. This is useful for debugging and understanding the tokenizer's behavior."]},{"cell_type":"markdown","id":"6963bbac","metadata":{"id":"6963bbac"},"source":["#### - Tokenizer Class Implementation"]},{"cell_type":"markdown","id":"4e569647-2589-4c9d-9a5c-aef1c88a0a9a","metadata":{"id":"4e569647-2589-4c9d-9a5c-aef1c88a0a9a"},"source":["- Putting it now all together into a tokenizer class"]},{"cell_type":"code","execution_count":14,"id":"f531bf46-7c25-4ef8-bff8-0d27518676d5","metadata":{"id":"f531bf46-7c25-4ef8-bff8-0d27518676d5","executionInfo":{"status":"ok","timestamp":1736783810794,"user_tz":-60,"elapsed":19,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}}},"outputs":[],"source":["class SimpleTokenizerV1:\n","    def __init__(self, vocab):\n","        self.str_to_int = vocab\n","        self.int_to_str = {i:s for s,i in vocab.items()}\n","\n","    def encode(self, text):\n","        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n","\n","        preprocessed = [\n","            item.strip() for item in preprocessed if item.strip()\n","        ]\n","        ids = [self.str_to_int[s] for s in preprocessed]\n","        return ids\n","\n","    def decode(self, ids):\n","        text = \" \".join([self.int_to_str[i] for i in ids])\n","        # Replace spaces before the specified punctuations\n","        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n","        return text"]},{"cell_type":"markdown","id":"dee7a1e5-b54f-4ca1-87ef-3d663c4ee1e7","metadata":{"id":"dee7a1e5-b54f-4ca1-87ef-3d663c4ee1e7"},"source":["- The `encode` function turns text into token IDs\n","- The `decode` function turns token IDs back into text"]},{"cell_type":"markdown","id":"19e8997f","metadata":{"id":"19e8997f"},"source":["**More details :**\n","- Encode Function: Converts raw text into token IDs using the vocabulary. It preprocesses the text by splitting it based on delimiters and maps tokens to their corresponding IDs.\n","- Decode Function: Reverses the process, converting token IDs back into a human-readable text format. It also removes unnecessary spaces near punctuation for better formatting."]},{"cell_type":"markdown","id":"c4f14449","metadata":{"id":"c4f14449"},"source":["#### - Tokenizer Encoding Example"]},{"cell_type":"markdown","id":"35154c2c","metadata":{"id":"35154c2c"},"source":["The class is tested on a sample text to verify its correctness."]},{"cell_type":"markdown","id":"cc21d347-ec03-4823-b3d4-9d686e495617","metadata":{"id":"cc21d347-ec03-4823-b3d4-9d686e495617"},"source":["<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/08.webp?123\" width=\"500px\">"]},{"cell_type":"markdown","id":"c2950a94-6b0d-474e-8ed0-66d0c3c1a95c","metadata":{"id":"c2950a94-6b0d-474e-8ed0-66d0c3c1a95c"},"source":["- We can use the tokenizer to encode (that is, tokenize) texts into integers\n","- These integers can then be embedded (later) as input of/for the LLM"]},{"cell_type":"code","execution_count":15,"id":"647364ec-7995-4654-9b4a-7607ccf5f1e4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"647364ec-7995-4654-9b4a-7607ccf5f1e4","executionInfo":{"status":"ok","timestamp":1736783811227,"user_tz":-60,"elapsed":451,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}},"outputId":"29e4df80-241f-4b82-f229-408b0827bbe5"},"outputs":[{"output_type":"stream","name":"stdout","text":["[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n"]}],"source":["tokenizer = SimpleTokenizerV1(vocab)\n","\n","text = \"\"\"\"It's the last he painted, you know,\"\n","           Mrs. Gisburn said with pardonable pride.\"\"\"\n","ids = tokenizer.encode(text)\n","print(ids)"]},{"cell_type":"markdown","id":"66bf42b8","metadata":{"id":"66bf42b8"},"source":["Purpose: Demonstrates that the tokenizer correctly maps text to token IDs, showcasing its effectiveness on structured English sentences."]},{"cell_type":"markdown","id":"894ccbd4","metadata":{"id":"894ccbd4"},"source":["#### - Tokenizer decoding Example"]},{"cell_type":"markdown","id":"3201706e-a487-4b60-b99d-5765865f29a0","metadata":{"id":"3201706e-a487-4b60-b99d-5765865f29a0"},"source":["- We can decode the integers back into text"]},{"cell_type":"code","execution_count":16,"id":"01d8c8fb-432d-4a49-b332-99f23b233746","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"01d8c8fb-432d-4a49-b332-99f23b233746","executionInfo":{"status":"ok","timestamp":1736783811228,"user_tz":-60,"elapsed":46,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}},"outputId":"8f284376-d1ab-4ed5-bf7b-02cf23adcee1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}],"source":["tokenizer.decode(ids)"]},{"cell_type":"markdown","id":"ca5032be","metadata":{"id":"ca5032be"},"source":["Purpose: This command takes a list of integer token IDs (ids) and decodes them back into their corresponding text strings. This step ensures that the encoding process accurately maps tokens to IDs and that the decoding process can reliably reverse this mapping."]},{"cell_type":"markdown","id":"5a2eca5f","metadata":{"id":"5a2eca5f"},"source":["#### - Validating Encoding and Decoding"]},{"cell_type":"code","execution_count":17,"id":"54f6aa8b-9827-412e-9035-e827296ab0fe","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"54f6aa8b-9827-412e-9035-e827296ab0fe","executionInfo":{"status":"ok","timestamp":1736783811228,"user_tz":-60,"elapsed":42,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}},"outputId":"18f8c480-4601-4bbe-f0bd-f12fb07377da"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":17}],"source":["tokenizer.decode(tokenizer.encode(text))"]},{"cell_type":"markdown","id":"ae78be24","metadata":{"id":"ae78be24"},"source":["Purpose: This line encodes the original text into token IDs and immediately decodes them back into text. The primary objective is to confirm that the tokenizer maintains consistency and accuracy throughout the encoding-decoding cycle."]},{"cell_type":"markdown","id":"4b821ef8-4d53-43b6-a2b2-aef808c343c7","metadata":{"id":"4b821ef8-4d53-43b6-a2b2-aef808c343c7"},"source":["## 2.4 Adding special context tokens"]},{"cell_type":"markdown","id":"3eb35965","metadata":{"id":"3eb35965"},"source":["Special tokens play a pivotal role in enhancing the tokenizer's functionality, particularly in handling unknown words and delineating text boundaries. This section introduces and integrates such tokens into the tokenizer's vocabulary."]},{"cell_type":"markdown","id":"863d6d15-a3e2-44e0-b384-bb37f17cf443","metadata":{"id":"863d6d15-a3e2-44e0-b384-bb37f17cf443"},"source":["- It's useful to add some \"special\" tokens for unknown words and to denote the end of a text"]},{"cell_type":"markdown","id":"aa7fc96c-e1fd-44fb-b7f5-229d7c7922a4","metadata":{"id":"aa7fc96c-e1fd-44fb-b7f5-229d7c7922a4"},"source":["<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/09.webp?123\" width=\"500px\">"]},{"cell_type":"markdown","id":"cfc37f53","metadata":{"id":"cfc37f53"},"source":["**Importance of Special Tokens**"]},{"cell_type":"markdown","id":"9d709d57-2486-4152-b7f9-d3e4bd8634cd","metadata":{"id":"9d709d57-2486-4152-b7f9-d3e4bd8634cd"},"source":["- Some tokenizers use special tokens to help the LLM with additional context\n","- Some of these special tokens are\n","  - `[BOS]` (beginning of sequence) marks the beginning of text\n","  - `[EOS]` (end of sequence) marks where the text ends (this is usually used to concatenate multiple unrelated texts, e.g., two different Wikipedia articles or two different books, and so on)\n","  - `[PAD]` (padding) if we train LLMs with a batch size greater than 1 (we may include multiple texts with different lengths; with the padding token we pad the shorter texts to the longest length so that all texts have an equal length)\n","- `[UNK]` to represent works that are not included in the vocabulary\n","\n","- Note that GPT-2 does not need any of these tokens mentioned above but only uses an `<|endoftext|>` token to reduce complexity\n","- The `<|endoftext|>` is analogous to the `[EOS]` token mentioned above\n","- GPT also uses the `<|endoftext|>` for padding (since we typically use a mask when training on batched inputs, we would not attend padded tokens anyways, so it does not matter what these tokens are)\n","- GPT-2 does not use an `<UNK>` token for out-of-vocabulary words; instead, GPT-2 uses a byte-pair encoding (BPE) tokenizer, which breaks down words into subword units which we will discuss in a later section\n","\n"]},{"cell_type":"markdown","id":"a336b43b-7173-49e7-bd80-527ad4efb271","metadata":{"id":"a336b43b-7173-49e7-bd80-527ad4efb271"},"source":["- We use the `<|endoftext|>` tokens between two independent sources of text:"]},{"cell_type":"markdown","id":"52442951-752c-4855-9752-b121a17fef55","metadata":{"id":"52442951-752c-4855-9752-b121a17fef55"},"source":["<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/10.webp\" width=\"500px\">"]},{"cell_type":"markdown","id":"670fba09","metadata":{"id":"670fba09"},"source":["#### - Handling Unknown Tokens"]},{"cell_type":"markdown","id":"c661a397-da06-4a86-ac27-072dbe7cb172","metadata":{"id":"c661a397-da06-4a86-ac27-072dbe7cb172"},"source":["- Let's see what happens if we tokenize the following text:"]},{"cell_type":"code","execution_count":18,"id":"d5767eff-440c-4de1-9289-f789349d6b85","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"id":"d5767eff-440c-4de1-9289-f789349d6b85","executionInfo":{"status":"error","timestamp":1736783811228,"user_tz":-60,"elapsed":40,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}},"outputId":"f483d106-29df-435e-85d2-784a81706a31"},"outputs":[{"output_type":"error","ename":"KeyError","evalue":"'Hello'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-d80f9ff7dada>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Hello, do you like tea. Is this-- a test?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-14-ce18d2cbde5a>\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreprocessed\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         ]\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr_to_int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreprocessed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-14-ce18d2cbde5a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreprocessed\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         ]\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr_to_int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreprocessed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Hello'"]}],"source":["tokenizer = SimpleTokenizerV1(vocab)\n","\n","text = \"Hello, do you like tea. Is this-- a test?\"\n","\n","tokenizer.encode(text)"]},{"cell_type":"markdown","id":"dc53ee0c-fe2b-4cd8-a946-5471f7651acf","metadata":{"id":"dc53ee0c-fe2b-4cd8-a946-5471f7651acf"},"source":["- The above produces an error because the word \"Hello\" is not contained in the vocabulary\n","- To deal with such cases, we can add special tokens like `\"<|unk|>\"` to the vocabulary to represent unknown words\n","- Since we are already extending the vocabulary, let's add another token called `\"<|endoftext|>\"` which is used in GPT-2 training to denote the end of a text (and it's also used between concatenated text, like if our training datasets consists of multiple articles, books, etc.)"]},{"cell_type":"markdown","id":"a6421c14","metadata":{"id":"a6421c14"},"source":["#### - Code Enhancement"]},{"cell_type":"code","execution_count":19,"id":"ce9df29c-6c5b-43f1-8c1a-c7f7b79db78f","metadata":{"id":"ce9df29c-6c5b-43f1-8c1a-c7f7b79db78f","executionInfo":{"status":"ok","timestamp":1736783851845,"user_tz":-60,"elapsed":261,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}}},"outputs":[],"source":["all_tokens = sorted(list(set(preprocessed)))\n","all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n","\n","vocab = {token:integer for integer,token in enumerate(all_tokens)}"]},{"cell_type":"markdown","id":"a9341340","metadata":{"id":"a9341340"},"source":["Purpose:\n","\n","- Vocabulary Expansion: Incorporates <|endoftext|> and <|unk|> into the existing set of tokens.\n","- Mapping Update: Reconstructs the vocab dictionary to include the newly added special tokens, assigning them unique integer IDs."]},{"cell_type":"markdown","id":"395af80c","metadata":{"id":"395af80c"},"source":["#### - Vocabulary Size:"]},{"cell_type":"code","execution_count":20,"id":"57c3143b-e860-4d3b-a22a-de22b547a6a9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"57c3143b-e860-4d3b-a22a-de22b547a6a9","executionInfo":{"status":"ok","timestamp":1736783852158,"user_tz":-60,"elapsed":24,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}},"outputId":"908e737a-86d8-4864-85ab-92e498d243cd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["1132"]},"metadata":{},"execution_count":20}],"source":["len(vocab.items())"]},{"cell_type":"markdown","id":"75767712","metadata":{"id":"75767712"},"source":["#### - Verification"]},{"cell_type":"markdown","id":"2beb0a2f","metadata":{"id":"2beb0a2f"},"source":["This indicates an expanded vocabulary accommodating the special tokens."]},{"cell_type":"code","execution_count":21,"id":"50e51bb1-ae05-4aa8-a9ff-455b65ed1959","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"50e51bb1-ae05-4aa8-a9ff-455b65ed1959","executionInfo":{"status":"ok","timestamp":1736783852543,"user_tz":-60,"elapsed":401,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}},"outputId":"30b46dfa-6125-47fb-bfaa-713e494d3035"},"outputs":[{"output_type":"stream","name":"stdout","text":["('younger', 1127)\n","('your', 1128)\n","('yourself', 1129)\n","('<|endoftext|>', 1130)\n","('<|unk|>', 1131)\n"]}],"source":["for i, item in enumerate(list(vocab.items())[-5:]):\n","    print(item)"]},{"cell_type":"markdown","id":"45853bd1","metadata":{"id":"45853bd1"},"source":["The inclusion of `<|endoftext|>` and `<|unk|>` is confirmed."]},{"cell_type":"markdown","id":"a1daa2b0-6e75-412b-ab53-1f6fb7b4d453","metadata":{"id":"a1daa2b0-6e75-412b-ab53-1f6fb7b4d453"},"source":["- We also need to adjust the tokenizer accordingly so that it knows when and how to use the new `<unk>` token"]},{"cell_type":"code","execution_count":22,"id":"948861c5-3f30-4712-a234-725f20d26f68","metadata":{"id":"948861c5-3f30-4712-a234-725f20d26f68","executionInfo":{"status":"ok","timestamp":1736783852543,"user_tz":-60,"elapsed":49,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}}},"outputs":[],"source":["class SimpleTokenizerV2:\n","    def __init__(self, vocab):\n","        self.str_to_int = vocab\n","        self.int_to_str = { i:s for s,i in vocab.items()}\n","\n","    def encode(self, text):\n","        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n","        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n","        preprocessed = [\n","            item if item in self.str_to_int\n","            else \"<|unk|>\" for item in preprocessed\n","        ]\n","\n","        ids = [self.str_to_int[s] for s in preprocessed]\n","        return ids\n","\n","    def decode(self, ids):\n","        text = \" \".join([self.int_to_str[i] for i in ids])\n","        # Replace spaces before the specified punctuations\n","        text = re.sub(r'\\s+([,.:;?!\"()\\'])', r'\\1', text)\n","        return text"]},{"cell_type":"markdown","id":"aa728dd1-9d35-4ac7-938f-d411d73083f6","metadata":{"id":"aa728dd1-9d35-4ac7-938f-d411d73083f6"},"source":["Let's try to tokenize text with the modified tokenizer:"]},{"cell_type":"code","execution_count":23,"id":"4133c502-18ac-4412-9f43-01caf4efa3dc","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4133c502-18ac-4412-9f43-01caf4efa3dc","executionInfo":{"status":"ok","timestamp":1736783852543,"user_tz":-60,"elapsed":48,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}},"outputId":"df27b34b-e54f-4231-fd7e-01a5b3552f4b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"]}],"source":["tokenizer = SimpleTokenizerV2(vocab)\n","\n","text1 = \"Hello, do you like tea?\"\n","text2 = \"In the sunlit terraces of the palace.\"\n","\n","text = \" <|endoftext|> \".join((text1, text2))\n","\n","print(text)"]},{"cell_type":"code","execution_count":24,"id":"7ed395fe-dc1b-4ed2-b85b-457cc35aab60","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ed395fe-dc1b-4ed2-b85b-457cc35aab60","executionInfo":{"status":"ok","timestamp":1736783852543,"user_tz":-60,"elapsed":39,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}},"outputId":"a3e87d1d-fb32-4817-9987-25289a8014b5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1131, 5, 355, 1126, 628, 975, 10, 1130, 55, 988, 956, 984, 722, 988, 1131, 7]"]},"metadata":{},"execution_count":24}],"source":["tokenizer.encode(text)"]},{"cell_type":"code","execution_count":25,"id":"059367f9-7a60-4c0d-8a00-7c4c766d0ebc","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"059367f9-7a60-4c0d-8a00-7c4c766d0ebc","executionInfo":{"status":"ok","timestamp":1736783852544,"user_tz":-60,"elapsed":34,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}},"outputId":"44866658-6f8c-4f6d-d175-86653d6c97be"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":25}],"source":["tokenizer.decode(tokenizer.encode(text))"]},{"cell_type":"markdown","id":"5c4ba34b-170f-4e71-939b-77aabb776f14","metadata":{"id":"5c4ba34b-170f-4e71-939b-77aabb776f14"},"source":["## 2.5 BytePair encoding"]},{"cell_type":"markdown","id":"58cb3bbd","metadata":{"id":"58cb3bbd"},"source":["Purpose : Byte Pair Encoding (BPE) is a subword tokenization technique that effectively handles OOV words by decomposing them into smaller, more frequent subword units. GPT-2 employs BPE to enhance its tokenizer's flexibility and efficiency."]},{"cell_type":"markdown","id":"2309494c-79cf-4a2d-bc28-a94d602f050e","metadata":{"id":"2309494c-79cf-4a2d-bc28-a94d602f050e"},"source":["**Overview of BPE**\n","- Functionality:\n","\n","  - Subword Tokenization: Breaks down rare or unknown words into constituent subwords or characters based on frequency, ensuring that the tokenizer can represent any possible word combination.\n","  - Vocabulary Efficiency: Maintains a manageable vocabulary size by combining frequent pairs of characters or subwords, reducing the likelihood of encountering OOV words.\n","\n","- Advantages:\n","\n","  - Robustness: Enhances the tokenizer's ability to handle diverse and complex linguistic inputs.\n","  - Efficiency: Balances coverage and computational efficiency by limiting the vocabulary size while maximizing representational capacity.\n","\n","- Reference Implementations:\n","\n","  - Original BPE Tokenizer: OpenAI GPT-2 Encoder\n","  - Optimized Implementation: tiktoken Library by OpenAI, which leverages Rust for improved performance.\n","  \n","- **Performance Benchmarking** : You have a notebook in the bytepair_encoder folder `(02_bonus_bytepair-encoder)` that compares these two implementations side-by-side (tiktoken was about 5x faster on the sample text)"]},{"cell_type":"markdown","id":"cd77b217","metadata":{"id":"cd77b217"},"source":["#### - Implementing BPE with tiktoken"]},{"cell_type":"markdown","id":"65dcb2fd","metadata":{"id":"65dcb2fd"},"source":["The tiktoken library is utilized to implement BPE tokenization, offering enhanced performance through its Rust-based core algorithms.\n","\n","#### - Installation and Version Verification"]},{"cell_type":"code","execution_count":26,"id":"ede1d41f-934b-4bf4-8184-54394a257a94","metadata":{"id":"ede1d41f-934b-4bf4-8184-54394a257a94","executionInfo":{"status":"ok","timestamp":1736783852544,"user_tz":-60,"elapsed":30,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}}},"outputs":[],"source":["# uncomment below to install tiktoken\n","# pip install tiktoken"]},{"cell_type":"markdown","id":"33e81e62","metadata":{"id":"33e81e62"},"source":["Purpose: Installs the tiktoken library, which is essential for BPE tokenization."]},{"cell_type":"code","execution_count":27,"id":"48967a77-7d17-42bf-9e92-fc619d63a59e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"48967a77-7d17-42bf-9e92-fc619d63a59e","executionInfo":{"status":"ok","timestamp":1736783852544,"user_tz":-60,"elapsed":28,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}},"outputId":"75784b3f-c60f-4a6a-ffc5-9927314e67df"},"outputs":[{"output_type":"stream","name":"stdout","text":["tiktoken version: 0.8.0\n"]}],"source":["import importlib\n","import tiktoken\n","\n","print(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))"]},{"cell_type":"markdown","id":"8a0ab293","metadata":{"id":"8a0ab293"},"source":["Purpose: Confirms the installation and checks the version of tiktoken."]},{"cell_type":"markdown","id":"90fb0595","metadata":{"id":"90fb0595"},"source":["#### - Initializing the tiktoken BPE Tokenizer"]},{"cell_type":"code","execution_count":28,"id":"6ad3312f-a5f7-4efc-9d7d-8ea09d7b5128","metadata":{"id":"6ad3312f-a5f7-4efc-9d7d-8ea09d7b5128","executionInfo":{"status":"ok","timestamp":1736783854198,"user_tz":-60,"elapsed":1674,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}}},"outputs":[],"source":["tokenizer = tiktoken.get_encoding(\"gpt2\")"]},{"cell_type":"markdown","id":"038e5cda","metadata":{"id":"038e5cda"},"source":["Purpose: Initializes the BPE tokenizer configured for GPT-2, aligning with the model's tokenization scheme."]},{"cell_type":"markdown","id":"fcf8d793","metadata":{"id":"fcf8d793"},"source":["#### - Tokenizing Text with tiktoken"]},{"cell_type":"code","execution_count":29,"id":"5ff2cd85-7cfb-4325-b390-219938589428","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ff2cd85-7cfb-4325-b390-219938589428","executionInfo":{"status":"ok","timestamp":1736783854199,"user_tz":-60,"elapsed":42,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}},"outputId":"e1571954-a8ba-4c3e-c61c-09d94732dc51"},"outputs":[{"output_type":"stream","name":"stdout","text":["[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n"]}],"source":["text = (\n","    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n","     \"of someunknownPlace.\"\n",")\n","\n","integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n","\n","print(integers)"]},{"cell_type":"markdown","id":"d5b3c764","metadata":{"id":"d5b3c764"},"source":["Purpose: Encodes a sample text into token IDs using the tiktoken BPE tokenizer.\n","\n","This list of integers represents the token IDs corresponding to the input text, including the special <|endoftext|> token."]},{"cell_type":"code","execution_count":30,"id":"d26a48bb-f82e-41a8-a955-a1c9cf9d50ab","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d26a48bb-f82e-41a8-a955-a1c9cf9d50ab","executionInfo":{"status":"ok","timestamp":1736783854200,"user_tz":-60,"elapsed":41,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}},"outputId":"29a6230c-81b7-4d2b-b7f9-36a2781e165a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"]}],"source":["strings = tokenizer.decode(integers)\n","\n","print(strings)"]},{"cell_type":"markdown","id":"5fae3b27","metadata":{"id":"5fae3b27"},"source":["Purpose: Decodes the previously obtained token IDs back into human-readable text to verify the accuracy of the tokenization process.\n","\n","The decoded text accurately reflects the original input, confirming the tokenizer's effectiveness."]},{"cell_type":"markdown","id":"efa8e712","metadata":{"id":"efa8e712"},"source":["#### - Visualizing BPE Tokenization"]},{"cell_type":"markdown","id":"e8c2e7b4-6a22-42aa-8e4d-901f06378d4a","metadata":{"id":"e8c2e7b4-6a22-42aa-8e4d-901f06378d4a"},"source":["- BPE tokenizers break down unknown words into subwords and individual characters:"]},{"cell_type":"markdown","id":"c082d41f-33d7-4827-97d8-993d5a84bb3c","metadata":{"id":"c082d41f-33d7-4827-97d8-993d5a84bb3c"},"source":["<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/11.webp\" width=\"300px\">"]},{"cell_type":"markdown","id":"abbd7c0d-70f8-4386-a114-907e96c950b0","metadata":{"id":"abbd7c0d-70f8-4386-a114-907e96c950b0"},"source":["## 2.6 Data sampling with a sliding window"]},{"cell_type":"markdown","id":"559d3b4f","metadata":{"id":"559d3b4f"},"source":["Efficient data sampling is paramount for training LLMs. A sliding window approach is employed to prepare input-target pairs, enabling the model to predict the next word in a sequence based on preceding context."]},{"cell_type":"markdown","id":"80e1f3bd","metadata":{"id":"80e1f3bd"},"source":["**Conceptual Framework**\n","- Objective: Train the model to generate one word at a time by predicting the subsequent word in a sequence.\n","\n","- Methodology:\n","\n","  - Sliding Window: Segments the tokenized text into overlapping chunks `(windows)` of a fixed size `(context_size)`, where each window serves as an input sequence, and the corresponding target is the same sequence shifted by one token.\n","\n","  - Input-Target Pairing: For each window, the input consists of tokens `[t1, t2, t3, t4]`, and the target is `[t2, t3, t4, t5]`. This setup trains the model to predict t5 given `[t1, t2, t3, t4]`."]},{"cell_type":"markdown","id":"509d9826-6384-462e-aa8a-a7c73cd6aad0","metadata":{"id":"509d9826-6384-462e-aa8a-a7c73cd6aad0"},"source":["- We train LLMs to generate one word at a time, so we want to prepare the training data accordingly where the next word in a sequence represents the target to predict:"]},{"cell_type":"markdown","id":"39fb44f4-0c43-4a6a-9c2f-9cf31452354c","metadata":{"id":"39fb44f4-0c43-4a6a-9c2f-9cf31452354c"},"source":["<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/12.webp\" width=\"400px\">"]},{"cell_type":"markdown","id":"83a948c3","metadata":{"id":"83a948c3"},"source":["#### - Code Implementation\n","Reading and Encoding the Dataset"]},{"cell_type":"code","execution_count":31,"id":"848d5ade-fd1f-46c3-9e31-1426e315c71b","metadata":{"id":"848d5ade-fd1f-46c3-9e31-1426e315c71b","outputId":"7e6b8111-4003-4bf0-fc1a-49d758ccb10a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736783854201,"user_tz":-60,"elapsed":36,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["5145\n"]}],"source":["with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n","    raw_text = f.read()\n","\n","enc_text = tokenizer.encode(raw_text)\n","print(len(enc_text))"]},{"cell_type":"markdown","id":"ee520b82","metadata":{"id":"ee520b82"},"source":["Purpose:\n","- Data Ingestion: Loads the text data from \"the-verdict.txt\".\n","- Tokenization: Encodes the entire text into token IDs using the BPE tokenizer.\n","\n","Output:\n","- Indicates that the encoded text consists of 5,145 tokens."]},{"cell_type":"markdown","id":"c43a099f","metadata":{"id":"c43a099f"},"source":["#### - Creating Input-Target Pairs"]},{"cell_type":"markdown","id":"cebd0657-5543-43ca-8011-2ae6bd0a5810","metadata":{"id":"cebd0657-5543-43ca-8011-2ae6bd0a5810"},"source":["- For each text chunk, we want the inputs and targets\n","- Since we want the model to predict the next word, the targets are the inputs shifted by one position to the right"]},{"cell_type":"code","execution_count":32,"id":"e84424a7-646d-45b6-99e3-80d15fb761f2","metadata":{"id":"e84424a7-646d-45b6-99e3-80d15fb761f2","executionInfo":{"status":"ok","timestamp":1736783854201,"user_tz":-60,"elapsed":32,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}}},"outputs":[],"source":["enc_sample = enc_text[50:]"]},{"cell_type":"markdown","id":"d56db7ee","metadata":{"id":"d56db7ee"},"source":["Purpose: Extracts a subset of the encoded text, starting from the 51st token, to ensure that the initial segment (possibly containing metadata or headers) doesn't interfere with training."]},{"cell_type":"markdown","id":"521b911e","metadata":{"id":"521b911e"},"source":["#### - Generating Input and Target Sequences"]},{"cell_type":"code","execution_count":33,"id":"dfbff852-a92f-48c8-a46d-143a0f109f40","metadata":{"id":"dfbff852-a92f-48c8-a46d-143a0f109f40","outputId":"b559470c-adac-4168-c307-bc52141119e7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736783854201,"user_tz":-60,"elapsed":31,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["x: [290, 4920, 2241, 287]\n","y:      [4920, 2241, 287, 257]\n"]}],"source":["context_size = 4\n","\n","x = enc_sample[:context_size]\n","y = enc_sample[1:context_size+1]\n","\n","print(f\"x: {x}\")\n","print(f\"y:      {y}\")"]},{"cell_type":"markdown","id":"cdfdc3b4","metadata":{"id":"cdfdc3b4"},"source":["Purpose:\n","- Input Sequence (x): The first four tokens [290, 4920, 2241, 287].\n","- Target Sequence (y): The next four tokens [4920, 2241, 287, 257], shifted by one position.\n","\n","Output:\n","- Demonstrates the alignment between inputs and their corresponding targets."]},{"cell_type":"markdown","id":"815014ef-62f7-4476-a6ad-66e20e42b7c3","metadata":{"id":"815014ef-62f7-4476-a6ad-66e20e42b7c3"},"source":["\n","- One by one, the prediction would look like as follows:\n"]},{"cell_type":"markdown","id":"edce132f","metadata":{"id":"edce132f"},"source":["#### - Visualizing Input-Target Alignment"]},{"cell_type":"code","execution_count":34,"id":"d97b031e-ed55-409d-95f2-aeb38c6fe366","metadata":{"id":"d97b031e-ed55-409d-95f2-aeb38c6fe366","outputId":"81865d9a-8af1-453c-a69f-532ad9d26c2d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736783854201,"user_tz":-60,"elapsed":25,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[290] ----> 4920\n","[290, 4920] ----> 2241\n","[290, 4920, 2241] ----> 287\n","[290, 4920, 2241, 287] ----> 257\n"]}],"source":["for i in range(1, context_size+1):\n","    context = enc_sample[:i]\n","    desired = enc_sample[i]\n","\n","    print(context, \"---->\", desired)"]},{"cell_type":"markdown","id":"76f17043","metadata":{"id":"76f17043"},"source":["Purpose: Iteratively displays how each token in the target sequence is derived from the input context."]},{"cell_type":"markdown","id":"d14d7efc","metadata":{"id":"d14d7efc"},"source":["#### - Decoding Input and Target Sequences"]},{"cell_type":"code","execution_count":35,"id":"f57bd746-dcbf-4433-8e24-ee213a8c34a1","metadata":{"id":"f57bd746-dcbf-4433-8e24-ee213a8c34a1","outputId":"442800d9-82e2-4ba6-c809-b3c905f0975f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736783854202,"user_tz":-60,"elapsed":20,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}}},"outputs":[{"output_type":"stream","name":"stdout","text":[" and ---->  established\n"," and established ---->  himself\n"," and established himself ---->  in\n"," and established himself in ---->  a\n"]}],"source":["for i in range(1, context_size+1):\n","    context = enc_sample[:i]\n","    desired = enc_sample[i]\n","\n","    print(tokenizer.decode(context), \"---->\", tokenizer.decode([desired]))"]},{"cell_type":"markdown","id":"d87f9588","metadata":{"id":"d87f9588"},"source":["Purpose:\n","- Decodes the numerical token IDs back into text to provide a clearer understanding of the input-target relationships.\n","\n","Output:\n","- Illustrates how each subsequent word is predicted based on the preceding context."]},{"cell_type":"markdown","id":"ce63e84d","metadata":{"id":"ce63e84d"},"source":["#### - Implementing a Data Loader"]},{"cell_type":"markdown","id":"210d2dd9-fc20-4927-8d3d-1466cf41aae1","metadata":{"id":"210d2dd9-fc20-4927-8d3d-1466cf41aae1"},"source":["We will take care of the next-word prediction in a later chapter after we covered the attention mechanism\n","\n","For now, we implement a simple data loader that iterates over the input dataset and returns the inputs and targets shifted by one"]},{"cell_type":"markdown","id":"a1a1b47a-f646-49d1-bc70-fddf2c840796","metadata":{"id":"a1a1b47a-f646-49d1-bc70-fddf2c840796"},"source":["- Install and import PyTorch (see Appendix A for installation tips)"]},{"cell_type":"code","execution_count":36,"id":"e1770134-e7f3-4725-a679-e04c3be48cac","metadata":{"id":"e1770134-e7f3-4725-a679-e04c3be48cac","outputId":"f8ea61e5-e57b-40c8-9179-579124d19192","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736783858792,"user_tz":-60,"elapsed":4605,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["PyTorch version: 2.5.1+cu121\n"]}],"source":["import torch\n","print(\"PyTorch version:\", torch.__version__)"]},{"cell_type":"markdown","id":"5b14bf40","metadata":{"id":"5b14bf40"},"source":["To streamline the training process, a data loader is implemented using PyTorch's Dataset and DataLoader classes. This loader efficiently iterates over the input dataset, yielding input-target pairs suitable for model training."]},{"cell_type":"markdown","id":"0c9a3d50-885b-49bc-b791-9f5cc8bc7b7c","metadata":{"id":"0c9a3d50-885b-49bc-b791-9f5cc8bc7b7c"},"source":["- We use a sliding window approach, changing the position by +1:\n","\n","<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/13.webp?123\" width=\"500px\">"]},{"cell_type":"markdown","id":"92ac652d-7b38-4843-9fbd-494cdc8ec12c","metadata":{"id":"92ac652d-7b38-4843-9fbd-494cdc8ec12c"},"source":["- Create dataset and dataloader that extract chunks from the input text dataset"]},{"cell_type":"code","execution_count":37,"id":"74b41073-4c9f-46e2-a1bd-d38e4122b375","metadata":{"id":"74b41073-4c9f-46e2-a1bd-d38e4122b375","executionInfo":{"status":"ok","timestamp":1736783858793,"user_tz":-60,"elapsed":9,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}}},"outputs":[],"source":["# Importing Required Modules\n","from torch.utils.data import Dataset, DataLoader\n","\n","# Defining the Custom Dataset Class\n","class GPTDatasetV1(Dataset):\n","    def __init__(self, txt, tokenizer, max_length, stride):\n","        self.input_ids = []\n","        self.target_ids = []\n","\n","        # Tokenize the entire text\n","        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n","\n","        # Use a sliding window to chunk the book into overlapping sequences of max_length\n","        for i in range(0, len(token_ids) - max_length, stride):\n","            input_chunk = token_ids[i:i + max_length]\n","            target_chunk = token_ids[i + 1: i + max_length + 1]\n","            self.input_ids.append(torch.tensor(input_chunk))\n","            self.target_ids.append(torch.tensor(target_chunk))\n","\n","    def __len__(self):\n","        return len(self.input_ids)\n","\n","    def __getitem__(self, idx):\n","        return self.input_ids[idx], self.target_ids[idx]"]},{"cell_type":"markdown","id":"7828fbca","metadata":{"id":"7828fbca"},"source":["**Purpose:**\n","- Initialization (__init__):\n","\n","  - Tokenization: Encodes the entire text into token IDs.\n","  - Sliding Window: Iterates over the token IDs with a specified stride, extracting overlapping input and target chunks of size max_length.\n","  - Storage: Stores the input and target chunks as PyTorch tensors for efficient retrieval.\n","- Length (__len__): Returns the total number of input-target pairs.\n","\n","- Item Retrieval (__getitem__): Provides access to individual input-target pairs based on the index."]},{"cell_type":"code","execution_count":38,"id":"5eb30ebe-97b3-43c5-9ff1-a97d621b3c4e","metadata":{"id":"5eb30ebe-97b3-43c5-9ff1-a97d621b3c4e","executionInfo":{"status":"ok","timestamp":1736783858793,"user_tz":-60,"elapsed":8,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}}},"outputs":[],"source":["# Creating the Data Loader Function\n","def create_dataloader_v1(txt, batch_size=4, max_length=256,\n","                         stride=128, shuffle=True, drop_last=True,\n","                         num_workers=0):\n","\n","    # Initialize the tokenizer\n","    tokenizer = tiktoken.get_encoding(\"gpt2\")\n","\n","    # Create dataset\n","    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n","\n","    # Create dataloader\n","    dataloader = DataLoader(\n","        dataset,\n","        batch_size=batch_size,\n","        shuffle=shuffle,\n","        drop_last=drop_last,\n","        num_workers=num_workers\n","    )\n","\n","    return dataloader"]},{"cell_type":"markdown","id":"84f2b75f","metadata":{"id":"84f2b75f"},"source":["**Purpose:**\n","- Tokenizer Initialization: Ensures consistency by using the same BPE tokenizer across the dataset.\n","\n","- Dataset Creation: Instantiates the GPTDatasetV1 class with the provided parameters.\n","\n","- DataLoader Configuration: Sets up the DataLoader with specified parameters such as batch_size, shuffle, drop_last, and num_workers to optimize data retrieval during training.\n","\n","- Return Value: Outputs the configured DataLoader for subsequent use in model training"]},{"cell_type":"markdown","id":"1a93ecea","metadata":{"id":"1a93ecea"},"source":["#### - Testing the Data Loader"]},{"cell_type":"markdown","id":"cbf86c9b","metadata":{"id":"cbf86c9b"},"source":["To validate the functionality of the data loader, it's tested with a batch size of 1 and a context size of 4."]},{"cell_type":"markdown","id":"42dd68ef-59f7-45ff-ba44-e311c899ddcd","metadata":{"id":"42dd68ef-59f7-45ff-ba44-e311c899ddcd"},"source":["#### - Loading the Raw Text"]},{"cell_type":"code","execution_count":39,"id":"df31d96c-6bfd-4564-a956-6192242d7579","metadata":{"id":"df31d96c-6bfd-4564-a956-6192242d7579","executionInfo":{"status":"ok","timestamp":1736783858793,"user_tz":-60,"elapsed":8,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}}},"outputs":[],"source":["with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n","    raw_text = f.read()"]},{"cell_type":"markdown","id":"f6f311fd","metadata":{"id":"f6f311fd"},"source":["Purpose: Reads the content of \"the-verdict.txt\" into the raw_text variable."]},{"cell_type":"markdown","id":"595fe43b","metadata":{"id":"595fe43b"},"source":["#### - Initializing the Data Loader and Iterating Over Batches"]},{"cell_type":"code","execution_count":40,"id":"9226d00c-ad9a-4949-a6e4-9afccfc7214f","metadata":{"id":"9226d00c-ad9a-4949-a6e4-9afccfc7214f","outputId":"59ce0c52-4a78-4c15-a946-7a57503ebe05","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736783859085,"user_tz":-60,"elapsed":299,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"]}],"source":["dataloader = create_dataloader_v1(\n","    raw_text, batch_size=1, max_length=4, stride=1, shuffle=False\n",")\n","\n","# - Parameters:\n","# batch_size=1: Processes one input-target pair at a time.\n","# max_length=4: Each input sequence contains four tokens.\n","# stride=1: The sliding window moves one token at a time, maximizing overlap and data utilization.\n","# shuffle=False: Maintains the original order of the data, which is essential for sequential tasks like language modeling.\n","\n","data_iter = iter(dataloader)\n","first_batch = next(data_iter)\n","print(first_batch)"]},{"cell_type":"markdown","id":"9396084d","metadata":{"id":"9396084d"},"source":["Purpose:\n","- Retrieves and prints the first input-target pair from the data loader.\n","\n","Output:\n","- Demonstrates the structure of the batch, consisting of tensors representing input and target sequences."]},{"cell_type":"code","execution_count":41,"id":"10deb4bc-4de1-4d20-921e-4b1c7a0e1a6d","metadata":{"id":"10deb4bc-4de1-4d20-921e-4b1c7a0e1a6d","outputId":"bafbdc70-2558-4945-d2dd-83edf49788f3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736783859085,"user_tz":-60,"elapsed":43,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]\n"]}],"source":["second_batch = next(data_iter)\n","print(second_batch)"]},{"cell_type":"markdown","id":"3e6e074f","metadata":{"id":"3e6e074f"},"source":["Further illustrates the sequential nature of input-target pairing."]},{"cell_type":"markdown","id":"7ae62c10","metadata":{"id":"7ae62c10"},"source":["#### - Visualizing Stride Equal to Context Length"]},{"cell_type":"markdown","id":"b006212f-de45-468d-bdee-5806216d1679","metadata":{"id":"b006212f-de45-468d-bdee-5806216d1679"},"source":["- An example using stride equal to the context length (here: 4) as shown below:"]},{"cell_type":"markdown","id":"9cb467e0-bdcd-4dda-b9b0-a738c5d33ac3","metadata":{"id":"9cb467e0-bdcd-4dda-b9b0-a738c5d33ac3"},"source":["<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/14.webp\" width=\"500px\">"]},{"cell_type":"markdown","id":"a8ddd6de","metadata":{"id":"a8ddd6de"},"source":["#### - Creating Batched Outputs\n","Adjusting the stride parameter affects the overlap between input sequences. By setting stride equal to max_length, overlapping is minimized, which can help prevent overfitting."]},{"cell_type":"markdown","id":"b1ae6d45-f26e-4b83-9c7b-cff55ffa7d16","metadata":{"id":"b1ae6d45-f26e-4b83-9c7b-cff55ffa7d16"},"source":["- We can also create batched outputs\n","- Note that we increase the stride here so that we don't have overlaps between the batches, since more overlap could lead to increased overfitting"]},{"cell_type":"code","execution_count":42,"id":"1916e7a6-f03d-4f09-91a6-d0bdbac5a58c","metadata":{"id":"1916e7a6-f03d-4f09-91a6-d0bdbac5a58c","outputId":"a6effd59-0079-42fb-a67a-e44145551561","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736783859085,"user_tz":-60,"elapsed":37,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Inputs:\n"," tensor([[   40,   367,  2885,  1464],\n","        [ 1807,  3619,   402,   271],\n","        [10899,  2138,   257,  7026],\n","        [15632,   438,  2016,   257],\n","        [  922,  5891,  1576,   438],\n","        [  568,   340,   373,   645],\n","        [ 1049,  5975,   284,   502],\n","        [  284,  3285,   326,    11]])\n","\n","Targets:\n"," tensor([[  367,  2885,  1464,  1807],\n","        [ 3619,   402,   271, 10899],\n","        [ 2138,   257,  7026, 15632],\n","        [  438,  2016,   257,   922],\n","        [ 5891,  1576,   438,   568],\n","        [  340,   373,   645,  1049],\n","        [ 5975,   284,   502,   284],\n","        [ 3285,   326,    11,   287]])\n"]}],"source":["dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n","\n","data_iter = iter(dataloader)\n","inputs, targets = next(data_iter)\n","print(\"Inputs:\\n\", inputs)\n","print(\"\\nTargets:\\n\", targets)\n","\n","# - Parameters:\n","# batch_size=8: Processes eight input-target pairs simultaneously.\n","# stride=4: Moves the sliding window by four tokens, ensuring no overlap between batches."]},{"cell_type":"markdown","id":"43e05344","metadata":{"id":"43e05344"},"source":["- Interpretation:\n","\n","  - Inputs: Each row represents an input sequence of four tokens.\n","  - Targets: Each corresponding row represents the target sequence, shifted by one token.\n","  - Stride Impact: With stride=4, there's no overlap between input sequences, reducing the risk of overfitting to specific patterns in the data."]},{"cell_type":"markdown","id":"2cd2fcda-2fda-4aa8-8bc8-de1e496f9db1","metadata":{"id":"2cd2fcda-2fda-4aa8-8bc8-de1e496f9db1"},"source":["## 2.7 Creating token embeddings"]},{"cell_type":"markdown","id":"cf656b68","metadata":{"id":"cf656b68"},"source":["Token embeddings are fundamental to LLMs, transforming discrete token IDs into continuous vector representations that capture semantic relationships and contextual nuances."]},{"cell_type":"markdown","id":"279b66f3","metadata":{"id":"279b66f3"},"source":["**Embedding Layer Overview**\n","- Functionality:\n","\n","  - Look-Up Operation: Maps each token ID to a corresponding embedding vector.\n","  - Trainable Parameters: Embedding vectors are learnable parameters optimized during model training to capture meaningful representations.\n","\n","- Relation to One-Hot Encoding:\n","\n","  - Efficiency: Embedding layers offer a more computationally efficient alternative to one-hot encoding, enabling scalable and dense representations.\n","  - Backpropagation: Unlike static one-hot vectors, embeddings can be fine-tuned via backpropagation, allowing the model to learn nuanced token relationships."]},{"cell_type":"markdown","id":"1a301068-6ab2-44ff-a915-1ba11688274f","metadata":{"id":"1a301068-6ab2-44ff-a915-1ba11688274f"},"source":["- The data is already almost ready for an LLM\n","- But lastly let us embed the tokens in a continuous vector representation using an embedding layer\n","- Usually, these embedding layers are part of the LLM itself and are updated (trained) during model training"]},{"cell_type":"markdown","id":"e85089aa-8671-4e5f-a2b3-ef252004ee4c","metadata":{"id":"e85089aa-8671-4e5f-a2b3-ef252004ee4c"},"source":["<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/15.webp\" width=\"400px\">"]},{"cell_type":"markdown","id":"44e014ca-1fc5-4b90-b6fa-c2097bb92c0b","metadata":{"id":"44e014ca-1fc5-4b90-b6fa-c2097bb92c0b"},"source":["- Suppose we have the following four input examples with input ids 2, 3, 5, and 1 (after tokenization):"]},{"cell_type":"code","execution_count":43,"id":"15a6304c-9474-4470-b85d-3991a49fa653","metadata":{"id":"15a6304c-9474-4470-b85d-3991a49fa653","executionInfo":{"status":"ok","timestamp":1736783859085,"user_tz":-60,"elapsed":30,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}}},"outputs":[],"source":["input_ids = torch.tensor([2, 3, 5, 1])"]},{"cell_type":"markdown","id":"14da6344-2c71-4837-858d-dd120005ba05","metadata":{"id":"14da6344-2c71-4837-858d-dd120005ba05"},"source":["- For the sake of simplicity, suppose we have a small vocabulary of only 6 words and we want to create embeddings of size 3:"]},{"cell_type":"code","execution_count":44,"id":"93cb2cee-9aa6-4bb8-8977-c65661d16eda","metadata":{"id":"93cb2cee-9aa6-4bb8-8977-c65661d16eda","executionInfo":{"status":"ok","timestamp":1736783859085,"user_tz":-60,"elapsed":29,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}}},"outputs":[],"source":["vocab_size = 6\n","output_dim = 3\n","\n","torch.manual_seed(123)\n","embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"]},{"cell_type":"markdown","id":"c6f43cb7","metadata":{"id":"c6f43cb7"},"source":["- Parameters:\n","\n","  - vocab_size=6: Defines the size of the vocabulary.\n","  - output_dim=3: Specifies the dimensionality of the embedding vectors.\n","\n","- Initialization:\n","\n","  - Random Seed: Ensures reproducibility by setting the random seed.\n","  - Embedding Matrix: Creates a weight matrix of shape (vocab_size, output_dim), where each row corresponds to a token's embedding."]},{"cell_type":"markdown","id":"3137cdf9","metadata":{"id":"3137cdf9"},"source":["#### - Embedding Layer Weights"]},{"cell_type":"markdown","id":"4ff241f6-78eb-4e4a-a55f-5b2b6196d5b0","metadata":{"id":"4ff241f6-78eb-4e4a-a55f-5b2b6196d5b0"},"source":["- This would result in a 6x3 weight matrix:"]},{"cell_type":"code","execution_count":45,"id":"a686eb61-e737-4351-8f1c-222913d47468","metadata":{"id":"a686eb61-e737-4351-8f1c-222913d47468","outputId":"2257e948-3342-4e0b-e479-d332cd0320b5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736783859085,"user_tz":-60,"elapsed":28,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Parameter containing:\n","tensor([[ 0.3374, -0.1778, -0.1690],\n","        [ 0.9178,  1.5810,  1.3010],\n","        [ 1.2753, -0.2010, -0.1606],\n","        [-0.4015,  0.9666, -1.1481],\n","        [-1.1589,  0.3255, -0.6315],\n","        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"]}],"source":["print(embedding_layer.weight)"]},{"cell_type":"markdown","id":"8f95570e","metadata":{"id":"8f95570e"},"source":["The embedding matrix consists of six 3-dimensional vectors, each representing a unique token in the vocabulary."]},{"cell_type":"markdown","id":"26fcf4f5-0801-4eb4-bb90-acce87935ac7","metadata":{"id":"26fcf4f5-0801-4eb4-bb90-acce87935ac7"},"source":["- For those who are familiar with one-hot encoding, the embedding layer approach above is essentially just a more efficient way of implementing one-hot encoding followed by matrix multiplication in a fully-connected layer, which is described in the supplementary code in (03_bonus_embedding-vs-matmul) folder.\n","- Because the embedding layer is just a more efficient implementation that is equivalent to the one-hot encoding and matrix-multiplication approach it can be seen as a neural network layer that can be optimized via backpropagation"]},{"cell_type":"markdown","id":"34d5d01c","metadata":{"id":"34d5d01c"},"source":["#### - Embedding a Single Token"]},{"cell_type":"markdown","id":"4b0d58c3-83c0-4205-aca2-9c48b19fd4a7","metadata":{"id":"4b0d58c3-83c0-4205-aca2-9c48b19fd4a7"},"source":["- To convert a token with id 3 into a 3-dimensional vector, we do the following:"]},{"cell_type":"code","execution_count":46,"id":"e43600ba-f287-4746-8ddf-d0f71a9023ca","metadata":{"id":"e43600ba-f287-4746-8ddf-d0f71a9023ca","outputId":"8d06510d-4145-44ee-d897-cc684dc6dc53","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736783859086,"user_tz":-60,"elapsed":21,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"]}],"source":["print(embedding_layer(torch.tensor([3])))"]},{"cell_type":"markdown","id":"8e1b678c","metadata":{"id":"8e1b678c"},"source":["This vector corresponds to the token with ID 3, showcasing its continuous representation."]},{"cell_type":"markdown","id":"e054bc7c","metadata":{"id":"e054bc7c"},"source":["#### - Embedding Multiple Tokens"]},{"cell_type":"markdown","id":"a7bbf625-4f36-491d-87b4-3969efb784b0","metadata":{"id":"a7bbf625-4f36-491d-87b4-3969efb784b0"},"source":["- Note that the above is the 4th row in the `embedding_layer` weight matrix\n","- To embed all four `input_ids` values above, we do"]},{"cell_type":"code","execution_count":47,"id":"50280ead-0363-44c8-8c35-bb885d92c8b7","metadata":{"id":"50280ead-0363-44c8-8c35-bb885d92c8b7","outputId":"6f85251e-bccb-4741-a135-a8260a2e6fd5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736783859086,"user_tz":-60,"elapsed":13,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 1.2753, -0.2010, -0.1606],\n","        [-0.4015,  0.9666, -1.1481],\n","        [-2.8400, -0.7849, -1.4096],\n","        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"]}],"source":["print(embedding_layer(input_ids))"]},{"cell_type":"markdown","id":"88b8f6eb","metadata":{"id":"88b8f6eb"},"source":["The resulting tensor has a shape of (4, 3), representing the embeddings for the four input tokens."]},{"cell_type":"markdown","id":"69e9cfd1","metadata":{"id":"69e9cfd1"},"source":["#### Representation of an embedding layer"]},{"cell_type":"markdown","id":"be97ced4-bd13-42b7-866a-4d699a17e155","metadata":{"id":"be97ced4-bd13-42b7-866a-4d699a17e155"},"source":["- An embedding layer is essentially a look-up operation:"]},{"cell_type":"markdown","id":"f33c2741-bf1b-4c60-b7fd-61409d556646","metadata":{"id":"f33c2741-bf1b-4c60-b7fd-61409d556646"},"source":["<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/16.webp\" width=\"500px\">"]},{"cell_type":"markdown","id":"1aef604b","metadata":{"id":"1aef604b"},"source":["**Supplementary Insights**\n","- Relation to Fully-Connected Layers:\n","\n","  - One-Hot Encoding Comparison: Embedding layers can be viewed as an efficient implementation of one-hot encoding followed by a linear transformation (matrix multiplication).\n","  - Trainability: Unlike static one-hot vectors, embedding layers are trainable, allowing the model to learn optimized representations during training.\n","- Further Reading: For an in-depth comparison between embedding layers and regular linear layers, refer to the supplementary notebook in (03_bonus_embedding-vs-matmul) folder."]},{"cell_type":"markdown","id":"c393d270-b950-4bc8-99ea-97d74f2ea0f6","metadata":{"id":"c393d270-b950-4bc8-99ea-97d74f2ea0f6"},"source":["## 2.8 Encoding word positions"]},{"cell_type":"markdown","id":"1f1afdd0","metadata":{"id":"1f1afdd0"},"source":["While token embeddings capture the semantic essence of tokens, they lack information about the token's position within the sequence. Positional embeddings address this limitation by encoding the position of each token, enabling the model to discern the order and structure of the input data."]},{"cell_type":"markdown","id":"6cf06b05","metadata":{"id":"6cf06b05"},"source":["#### - Challenge of Position-Invariant Embeddings\n","- Issue: Standard embedding layers treat each token ID independently of its position, making the model agnostic to the order of tokens.\n","\n","- Implication: Without positional information, the model cannot capture the sequential nature of language, which is critical for understanding context and generating coherent text."]},{"cell_type":"markdown","id":"24940068-1099-4698-bdc0-e798515e2902","metadata":{"id":"24940068-1099-4698-bdc0-e798515e2902"},"source":["- Embedding layer convert IDs into identical vector representations regardless of where they are located in the input sequence:"]},{"cell_type":"markdown","id":"9e0b14a2-f3f3-490e-b513-f262dbcf94fa","metadata":{"id":"9e0b14a2-f3f3-490e-b513-f262dbcf94fa"},"source":["<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/17.webp\" width=\"400px\">"]},{"cell_type":"markdown","id":"460811f6","metadata":{"id":"460811f6"},"source":["#### - Introducing Positional Embeddings\n","\n","- Functionality:\n","\n","  - Positional Encoding: Assigns unique vectors to each position in the input sequence, which are then combined with token embeddings.\n","  - Integration: The sum of token and positional embeddings forms the final input embeddings fed into the LLM.\n","\n","- Implementation in GPT-2:\n","\n","  - Absolute Positional Embeddings: GPT-2 employs absolute positional embeddings, meaning each position has a distinct embedding irrespective of the context.\n","  - Efficiency: By maintaining separate embedding layers for tokens and positions, the model efficiently integrates both semantic and positional information."]},{"cell_type":"markdown","id":"92a7d7fe-38a5-46e6-8db6-b688887b0430","metadata":{"id":"92a7d7fe-38a5-46e6-8db6-b688887b0430"},"source":["- Positional embeddings are combined with the token embedding vector to form the input embeddings for a large language model:"]},{"cell_type":"markdown","id":"48de37db-d54d-45c4-ab3e-88c0783ad2e4","metadata":{"id":"48de37db-d54d-45c4-ab3e-88c0783ad2e4"},"source":["<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/18.webp\" width=\"500px\">"]},{"cell_type":"markdown","id":"a7941f4c","metadata":{"id":"a7941f4c"},"source":["#### - Code Implementation: Initializing Embedding Layers"]},{"cell_type":"markdown","id":"7f187f87-c1f8-4c2e-8050-350bbb972f55","metadata":{"id":"7f187f87-c1f8-4c2e-8050-350bbb972f55"},"source":["- The BytePair encoder has a vocabulary size of 50,257:\n","- Suppose we want to encode the input tokens into a 256-dimensional vector representation:"]},{"cell_type":"code","execution_count":48,"id":"0b9e344d-03a6-4f2c-b723-67b6a20c5041","metadata":{"id":"0b9e344d-03a6-4f2c-b723-67b6a20c5041","executionInfo":{"status":"ok","timestamp":1736783859471,"user_tz":-60,"elapsed":392,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}}},"outputs":[],"source":["vocab_size = 50257\n","output_dim = 256\n","\n","token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"]},{"cell_type":"markdown","id":"1691a9ce","metadata":{"id":"1691a9ce"},"source":["- Parameters:\n","  - vocab_size=50257: Aligns with GPT-2's extensive vocabulary size.\n","  - output_dim=256: Sets the dimensionality of each embedding vector, balancing expressiveness and computational efficiency."]},{"cell_type":"markdown","id":"0a9d8d77","metadata":{"id":"0a9d8d77"},"source":["#### - Embedding Tokens from the Data Loader"]},{"cell_type":"markdown","id":"a2654722-24e4-4b0d-a43c-436a461eb70b","metadata":{"id":"a2654722-24e4-4b0d-a43c-436a461eb70b"},"source":["- If we sample data from the dataloader, we embed the tokens in each batch into a 256-dimensional vector\n","- If we have a batch size of 8 with 4 tokens each, this results in a 8 x 4 x 256 tensor:"]},{"cell_type":"code","execution_count":49,"id":"ad56a263-3d2e-4d91-98bf-d0b68d3c7fc3","metadata":{"id":"ad56a263-3d2e-4d91-98bf-d0b68d3c7fc3","executionInfo":{"status":"ok","timestamp":1736783859472,"user_tz":-60,"elapsed":42,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}}},"outputs":[],"source":["max_length = 4\n","dataloader = create_dataloader_v1(\n","    raw_text, batch_size=8, max_length=max_length,\n","    stride=max_length, shuffle=False\n",")\n","data_iter = iter(dataloader)\n","inputs, targets = next(data_iter)"]},{"cell_type":"markdown","id":"438e6f64","metadata":{"id":"438e6f64"},"source":["Purpose:\n","- Batch Configuration: Processes eight sequences (batch_size=8) each containing four tokens (max_length=4).\n","- Stride Adjustment: Sets stride=4 to eliminate overlap between sequences, reducing redundancy and potential overfitting."]},{"cell_type":"markdown","id":"21e787f2","metadata":{"id":"21e787f2"},"source":["#### - Inspecting Token IDs and Input Shape"]},{"cell_type":"code","execution_count":50,"id":"84416b60-3707-4370-bcbc-da0b62f2b64d","metadata":{"id":"84416b60-3707-4370-bcbc-da0b62f2b64d","outputId":"5645da1d-b2a3-40fb-bc39-17a0c4566393","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736783859472,"user_tz":-60,"elapsed":40,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Token IDs:\n"," tensor([[   40,   367,  2885,  1464],\n","        [ 1807,  3619,   402,   271],\n","        [10899,  2138,   257,  7026],\n","        [15632,   438,  2016,   257],\n","        [  922,  5891,  1576,   438],\n","        [  568,   340,   373,   645],\n","        [ 1049,  5975,   284,   502],\n","        [  284,  3285,   326,    11]])\n","\n","Inputs shape:\n"," torch.Size([8, 4])\n"]}],"source":["print(\"Token IDs:\\n\", inputs)\n","print(\"\\nInputs shape:\\n\", inputs.shape)"]},{"cell_type":"markdown","id":"1b9a978e","metadata":{"id":"1b9a978e"},"source":["- Token IDs: Displays the token sequences for the batch.\n","- Input Shape: Confirms that the input tensor has a shape of (8, 4), representing eight sequences each of four tokens."]},{"cell_type":"markdown","id":"30307454","metadata":{"id":"30307454"},"source":["#### - Embedding the Tokens"]},{"cell_type":"code","execution_count":51,"id":"7766ec38-30d0-4128-8c31-f49f063c43d1","metadata":{"id":"7766ec38-30d0-4128-8c31-f49f063c43d1","outputId":"eb6bc5d8-e49f-4a01-a820-18de9586a255","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736783859473,"user_tz":-60,"elapsed":37,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([8, 4, 256])\n"]}],"source":["token_embeddings = token_embedding_layer(inputs)\n","print(token_embeddings.shape)"]},{"cell_type":"markdown","id":"1a8e1be3","metadata":{"id":"1a8e1be3"},"source":["Indicates that each token in the input sequences is mapped to a 256-dimensional embedding vector, resulting in a tensor of shape (8, 4, 256)."]},{"cell_type":"markdown","id":"4449959f","metadata":{"id":"4449959f"},"source":["#### - Positional Embeddings Initialization"]},{"cell_type":"markdown","id":"fe2ae164-6f19-4e32-b9e5-76950fcf1c9f","metadata":{"id":"fe2ae164-6f19-4e32-b9e5-76950fcf1c9f"},"source":["- GPT-2 uses absolute position embeddings, so we just create another embedding layer:"]},{"cell_type":"code","execution_count":52,"id":"cc048e20-7ac8-417e-81f5-8fe6f9a4fe07","metadata":{"id":"cc048e20-7ac8-417e-81f5-8fe6f9a4fe07","executionInfo":{"status":"ok","timestamp":1736783859474,"user_tz":-60,"elapsed":30,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}}},"outputs":[],"source":["context_length = max_length\n","pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)"]},{"cell_type":"markdown","id":"ab5c61db","metadata":{"id":"ab5c61db"},"source":["- Parameters:\n","  - context_length=4: Matches the maximum sequence length.\n","  - output_dim=256: Aligns with the token embedding dimensionality for seamless integration."]},{"cell_type":"markdown","id":"7328fddc","metadata":{"id":"7328fddc"},"source":["#### - Generating Positional Embeddings"]},{"cell_type":"code","execution_count":53,"id":"c369a1e7-d566-4b53-b398-d6adafb44105","metadata":{"id":"c369a1e7-d566-4b53-b398-d6adafb44105","outputId":"da2cd523-58d1-4934-a214-1b6c4ef838cf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736783859474,"user_tz":-60,"elapsed":28,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4, 256])\n"]}],"source":["pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n","print(pos_embeddings.shape)"]},{"cell_type":"markdown","id":"c2503407","metadata":{"id":"c2503407"},"source":["The positional embeddings tensor has a shape of (4, 256), representing the embeddings for each position in the sequence."]},{"cell_type":"markdown","id":"ab14d67e","metadata":{"id":"ab14d67e"},"source":["#### - Combining Token and Positional Embeddings"]},{"cell_type":"markdown","id":"870e9d9f-2935-461a-9518-6d1386b976d6","metadata":{"id":"870e9d9f-2935-461a-9518-6d1386b976d6"},"source":["- To create the input embeddings used in an LLM, we simply add the token and the positional embeddings:"]},{"cell_type":"code","execution_count":54,"id":"b22fab89-526e-43c8-9035-5b7018e34288","metadata":{"id":"b22fab89-526e-43c8-9035-5b7018e34288","outputId":"95fe49ab-4673-4fb9-8169-6ea05466ea3e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736783859474,"user_tz":-60,"elapsed":20,"user":{"displayName":"Nicolas CHARPENTIER","userId":"18267342722895877832"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([8, 4, 256])\n"]}],"source":["input_embeddings = token_embeddings + pos_embeddings\n","print(input_embeddings.shape)"]},{"cell_type":"markdown","id":"af560a87","metadata":{"id":"af560a87"},"source":["The addition of token and positional embeddings results in a tensor of shape (8, 4, 256), which serves as the comprehensive input embeddings incorporating both semantic and positional information."]},{"cell_type":"markdown","id":"12221525","metadata":{"id":"12221525"},"source":["#### - Representation"]},{"cell_type":"markdown","id":"1fbda581-6f9b-476f-8ea7-d244e6a4eaec","metadata":{"id":"1fbda581-6f9b-476f-8ea7-d244e6a4eaec"},"source":["- In the initial phase of the input processing workflow, the input text is segmented into separate tokens\n","- Following this segmentation, these tokens are transformed into token IDs based on a predefined vocabulary:"]},{"cell_type":"markdown","id":"d1bb0f7e-460d-44db-b366-096adcd84fff","metadata":{"id":"d1bb0f7e-460d-44db-b366-096adcd84fff"},"source":["<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/19.webp\" width=\"400px\">"]},{"cell_type":"markdown","id":"235869fa","metadata":{"id":"235869fa"},"source":["#### - Final Integration in the Input Processing Workflow\n","- Segmentation: The input text is first segmented into tokens using the BPE tokenizer.\n","\n","- Encoding: Tokens are transformed into integer IDs based on the extended vocabulary, which now includes special tokens.\n","\n","- Embedding: Token IDs are mapped to continuous vectors via the embedding layer.\n","\n","- Positional Encoding: Positional embeddings are generated and added to the token embeddings to incorporate sequence order information.\n","\n","- Result: The final input embeddings are a combination of token semantics and positional context, ready to be fed into the LLM for training."]},{"cell_type":"markdown","id":"63230f2e-258f-4497-9e2e-8deee4530364","metadata":{"id":"63230f2e-258f-4497-9e2e-8deee4530364"},"source":["# Summary and takeaways"]},{"cell_type":"markdown","id":"8b3293a6-45a5-47cd-aa00-b23e3ca0a73f","metadata":{"id":"8b3293a6-45a5-47cd-aa00-b23e3ca0a73f"},"source":["This chapter meticulously guided the development of a tokenizer tailored for LLMs, highlighting the significance of handling unknown tokens and incorporating positional information. Key takeaways include:\n","\n","- Tokenizer Robustness: Incorporating special tokens like <|unk|> and <|endoftext|> enhances the tokenizer's ability to handle diverse and unpredictable text inputs.\n","\n","- Byte Pair Encoding (BPE): BPE serves as an effective method for subword tokenization, balancing vocabulary size and flexibility, thereby enabling models like GPT-2 to manage OOV words efficiently.\n","\n","- Data Sampling Strategy: The sliding window approach for data sampling ensures that the model is exposed to varied contexts, fostering better generalization during training.\n","\n","- Embedding Layers: Transforming token IDs into continuous vectors via embedding layers is fundamental for capturing semantic relationships, while positional embeddings are crucial for maintaining the sequential integrity of the input data.\n","\n","- Integration Workflow: The seamless combination of token and positional embeddings establishes a solid foundation for feeding data into LLMs, setting the stage for subsequent training and model development phases.\n","\n","#### - Additional Resources\n","- See the `dataloader.ipynb` code notebook in (04_bonus_dataloader-intuition) folder, which is a concise version of the data loader that we implemented in this chapter and will need for training the GPT model in upcoming chapters..\n","\n","- Exercise Solutions: To validate this lab , you will need to complete the two exercises in the notebook `exercise.ipynb` in the (01_main-code folder).\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}